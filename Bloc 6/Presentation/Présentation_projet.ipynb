{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprendre la langue des signes à l'aide de l'IA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problématique : \n",
    "    * En langue des signes, il est difficile de trouver la définition d'un objet, d'un animal.. si c'est la première fois qu'on le voit!\n",
    "    * Il est plus simple de se comprendre si l'on parle de la même chose !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le projet : \n",
    "    1)  Entraîner un algorithme d'Inteligence Artificiel pour reconnaitre un objet, un animal etc..\n",
    "    2)  Utiliser la prédiction de l'IA ainsi que l'API SignesDeSens pour traduire l'objet en langue des signes.\n",
    "    3)  Prendre une photo d'un objet... dont on ne connait pas la définition en langue des signes, et le traduire.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les objectifs :\n",
    "    * Algorithme et dataset :\n",
    "        - Dans un premier temps entrainer un algorithme pour la reconnaisance d'objet. Récupérer une architecture ('Mobilnet' par exemple),\n",
    "        avec le poids de ImageNet.\n",
    "        - Trouver des Datasets qui contiennent l'ensemble des classes souhaitées pour la reconnaissance d'object. Dataset récupérer grâce à \"Open Image V6\".\n",
    "        - Travailler sur les dernières couches pour trouver les meilleures performances de l'algorithme dans la prédiction.\n",
    "        - Dans un second temps(si on a le temps), travailler sur un algorithme pour le reconnaissance d'animaux avec TensorHub ('Voir l'exercie tensorhub').\n",
    "    \n",
    "    * Traduction en langue des signes : \n",
    "        - Grâce à l'API de l'association \"SignesDeSens\", il est possible, à partir d'un mot, de remonter à sa définition en langue des signes. Porblème : Ils sont en vacances, je vais faire mes propres vidéos \n",
    "    \n",
    "    * Déploiment d'algorithme :\n",
    "        - Permettre le déploiment de l'algorithme.\n",
    "        - Prendre une photo qu'on donne à lIA.\n",
    "        - Avoir une prediction et afficher sa traduction en langue des signe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création app.py\n",
    "    * Je vais créer un fichier .py qui contient la bibliothèque Flask, dont l'objectif est de d'arriver à une interface :\n",
    "    - présentation du projet\n",
    "    - chargement des la photo à prédire\n",
    "    - arriver sur une autre page avec la prédiction, la vidéo qui traduit en langue des signes, le mot écrit avec l'alphabet de langue des signes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les points pour améliorer le projet (à compléter à chaque idée, même mauvaise):\n",
    "\n",
    "    * En plus de donner la vidéo en langue des signes, décomposer le mot et traduire chaque lettre pour une meilleure décomposition du mot\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement du Dataset et des différentes classes !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Télécharger les image avec open image V6\n",
    "\n",
    "https://storage.googleapis.com/openimages/web/visualizer/index.html?set=train&type=segmentation&r=false&c=%2Fm%2F01f8m5\n",
    "\n",
    "    Le téléchargement des images s'effectue avec le shell d'Anaconda!\n",
    "    Voici les différentes étapes : \n",
    "        * git clone https://github.com/theAIGuysCode/OIDv4_ToolKit.git #permet de charger l'ensemble de pack permettant le téléchargement des photos\n",
    "        * cd OIDv4_ToolKit # Permet de rentrer dans le fichier créé à la suite de la première commande\n",
    "        * pip install -r requirements.txt # Cette fonction va permettre de mettre un label sur nos photos\n",
    "        * python main.py downloader --classes Coffee Tea --type_csv train --multiclass 1 --limit 20 # C'est cette commande qui va télécharger nos photos. Dans --classes on y rentre les différentes classe que l'on souhaite abtenir. Dans --type_csv on indique train, test ou val. Dans --multiclass On met 1, cela permettra d'avoir 1 seul dossier qui contient toutes nos classes aulieu d'avoir un dossier par classe. Dans --limet on inique le nombre de photo que l'on souhaite télécharger.\n",
    "        * Dans le fichier classes qui se trouve dans le dossier OIDv4_ToolKit, rentre les différentes classes qui ont été téléchargé\n",
    "        * python convert_annotations.py # Cette commande va permettre d'associer un label à chaque photo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition\n",
    "\n",
    "    Dans le notebook \"Def_Preprocessing_models\" du dossier \"Code_python\" on retrouve toutes les definitions qui ont été créée pour la recherche d'un bon model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Résultats :\n",
    "\n",
    "    L'ensemble des résultats sont résumés dans le notebook \"Résultats\" dans le dossier \"Test_DL\". Ce notebook résume les models utilisés et leur résultats. \n",
    "    Les premier résultats ont été réalisés sur 6 catégories (Dog, Cat, Knife, Guitar, Ball, Camera).\n",
    "\n",
    "    Conclusion des premiers Test : \n",
    "    \n",
    " ### Cette partie n'est pas complète"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataSet\n",
    "\n",
    "    Il sera composé de 25 classes : Apple, Backpack, Banana, Binoculars, Bottle, Calculator, Candle, Canoe, Dress, Hat, Mug, sandwich, Zebra, Bear, Cat, Dog, Elephant, Knife, Flower, Goat, Guitar, Pizza, Monkey, Turtle, Watch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOURETOUT\n",
    "\n",
    "\n",
    "    Python-multipart pour que FastAPI puisse recevoir des images en paramètre."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
